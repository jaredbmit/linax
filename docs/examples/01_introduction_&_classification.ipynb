{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40aba578",
   "metadata": {},
   "source": [
    "# Sequence Classification with linax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dac22d",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to train LinOSS[2] on the [MNIST SEQUENCE](https://edwin-de-jong.github.io/blog/mnist-sequence-data/) dataset using [`JAX`](https://github.com/google/jax), [`Equinox`](https://github.com/patrick-kidger/equinox) and **[`Linax`](https://github.com/tk-rusch/linoss)**.\n",
    "\n",
    "### About Linax\n",
    "\n",
    "**Linax** is a library for state-space sequence modeling built on JAX and Equinox. It provides:\n",
    "\n",
    "- **Modern SSM architectures**: LRU, LinOSS and other state-of-the-art models\n",
    "- **JAX-native**: JIT compilation and automatic differentiation\n",
    "- **Clean API**: Built on Equinox for a PyTorch-like feel.\n",
    "\n",
    "### About LinOSS\n",
    "\n",
    "LinOSS (Linear Oscillatory State-Space) is a state-space sequence model based on forced harmonic oscillators, modeled after a system of independent, forced linear second-order ODEs.\n",
    "\n",
    "### About the Dataset\n",
    "\n",
    "In this example, we use the **MNIST Sequence dataset**, where handwritten digits are represented as sequences of pen strokes. Each timestep contains **4 features**:\n",
    "\n",
    "- **dx, dy**: Pen movement offsets (relative displacement from previous position)\n",
    "- **eos** (end-of-stroke): Binary flag indicating when the pen lifts off (value = 1)\n",
    "- **eod** (end-of-digit): Binary flag indicating the end of the digit sequence (value = 1)\n",
    "\n",
    "This encoding captures the **temporal dynamics** of how each digit was drawn, treating handwriting as a sequential process rather than a static image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce846cce",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We use:\n",
    "- **Linax** - Our SSM library providing the core building blocks\n",
    "- **JAX/Equinox** - Foundation libraries for the model definition and training loop\n",
    "- **PyTorch** - For efficient data loading via DataLoader (converted to NumPy for JAX)\n",
    "- **Optax** - For optimization\n",
    "- **jaxtyping** - For type annotations with array shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b508772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import torch\n",
    "from datasets import MNISTSeq\n",
    "from jaxtyping import Array, Float, Int, PRNGKeyArray, PyTree\n",
    "from tqdm import tqdm\n",
    "\n",
    "from linax.encoder import LinearEncoderConfig\n",
    "from linax.heads.classification import ClassificationHeadConfig\n",
    "from linax.models.linoss import LinOSSConfig\n",
    "from linax.models.ssm import SSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e57527",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "We define our training configuration. These values have been chosen for effective training:\n",
    "\n",
    "- **Batch Size**: 32 samples per batch (good balance between speed and stability)\n",
    "- **Learning Rate**: $3 \\times 10^{-4}$\n",
    "- **Steps**: 7500 training steps (approximately 5 epochs)\n",
    "- **Print Every**: for evaluating every $1500$ steps (approximately every epoch)\n",
    "- **Num Blocks**: 10 LinOSS blocks for the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c6a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "# With these parameters the training time is around 17 minutes.\n",
    "BATCH_SIZE = 32  # Number of samples per batch\n",
    "LEARNING_RATE = 3e-4  # AdamW learning rate\n",
    "STEPS = 7500  # Total training steps.\n",
    "PRINT_EVERY = 1500  # Evaluation frequency.\n",
    "SEED = 5678  # Random seed for reproducibility\n",
    "NUM_BLOCKS = 10  # Number of LinOSS blocks\n",
    "\n",
    "# random keys take care of randomness in JAX\n",
    "key = jax.random.PRNGKey(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a57c1e8",
   "metadata": {},
   "source": [
    "## Data Loading üìä\n",
    "\n",
    "We load the **MNIST Sequence dataset** where handwritten digits are represented as sequences of pen strokes.\n",
    "\n",
    "### Dataset Details:\n",
    "- **Sequences**: Each sample is 128 timesteps long\n",
    "- **Features**: 4 features per timestep\n",
    "  - `dx, dy`: Pen movement offsets (relative displacement)\n",
    "  - `eos`: End-of-stroke marker (pen lift)\n",
    "  - `eod`: End-of-digit marker (sequence end)\n",
    "- **Labels**: Digit class (0-9)\n",
    "\n",
    "### Preprocessing:\n",
    "The `MNISTSeq` dataset automatically:\n",
    "1. Downloads the data from the official source\n",
    "2. Pads/truncates sequences to fixed length (128)\n",
    "3. Returns PyTorch tensors (which we convert to NumPy for JAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST Sequence dataset\n",
    "train_dataset = MNISTSeq(root=\"../../data_dir\", train=True, download=True)\n",
    "\n",
    "test_dataset = MNISTSeq(root=\"../../data_dir\", train=False, download=True)\n",
    "\n",
    "# Create DataLoaders for efficient batching\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e30c4",
   "metadata": {},
   "source": [
    "## Inspecting the Data üîç\n",
    "\n",
    "Let's verify our data shapes and examine a sample batch to ensure everything is loaded correctly.\n",
    "\n",
    "**Expected shapes:**\n",
    "- `x`: `(batch_size, 128, 4)` - sequences of pen strokes with 4 features per timestep\n",
    "- `y`: `(batch_size,)` - class labels (digits 0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "374dbf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (32, 128, 4)\n",
      "Label shape: (32,)\n",
      "Sample labels: [7 2 2 4 2 9 7 1 6 3 2 2 9 1 3 4 7 3 1 0 2 1 3 2 7 1 0 7 1 4 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Get a sample batch to verify shapes\n",
    "dummy_x, dummy_y = next(iter(trainloader))\n",
    "dummy_x = dummy_x.numpy()\n",
    "dummy_y = dummy_y.numpy()\n",
    "print(f\"Input shape: {dummy_x.shape}\")  # (batch_size, 128, 4)\n",
    "print(f\"Label shape: {dummy_y.shape}\")  # (batch_size,)\n",
    "print(f\"Sample labels: {dummy_y}\")  # Example digit labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b28dcc",
   "metadata": {},
   "source": [
    "### Visualizing MNIST Sequences\n",
    "\n",
    "Let's visualize some samples from the training set to see what our model will be learning from. Each visualization shows how the pen strokes form the digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "983f6939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset.plot_samples(num_samples=4, figsize=(4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3884a0",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "We'll build a LinOSS model using Linax's configuration system. The model consists of three main components:\n",
    "\n",
    "1. **Encoder**: Transforms input sequences (4 features) to a higher-dimensional space (64 features)\n",
    "2. **SSM Blocks**: Stacked LinOSS blocks that process the sequences using oscillatory dynamics\n",
    "3. **Classification Head**: Maps the final representation to class probabilities (10 digits)\n",
    "\n",
    "### Configuration Parameters:\n",
    "\n",
    "- `num_blocks`: Number of stacked LinOSS layers (configurable via `NUM_BLOCKS`)\n",
    "- `encoder_config`: Defines the input projection (4 ‚Üí 64 dimensions)\n",
    "- `head_config`: Defines the output layer (64 ‚Üí 10 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e26e1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "linoss_cfg = LinOSSConfig(\n",
    "    num_blocks=NUM_BLOCKS,\n",
    "    encoder_config=LinearEncoderConfig(in_features=4, out_features=64),\n",
    "    head_config=ClassificationHeadConfig(out_features=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf82fd5",
   "metadata": {},
   "source": [
    "Next, we build the model from the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b2998ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key, 2)\n",
    "\n",
    "model = linoss_cfg.build(key=subkey)\n",
    "\n",
    "state = eqx.nn.State(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c22c11c",
   "metadata": {},
   "source": [
    "### Model Summary\n",
    "\n",
    "Let's inspect the model to see its architecture and parameter count. \n",
    "\n",
    "**What to look for:**\n",
    "- Total parameters (scales with `NUM_BLOCKS` - lightweight for sequence modeling!)\n",
    "- Each block has ~25K parameters\n",
    "- IMEX discretization scheme for numerical stability\n",
    "- Dropout rate of 0.1 for regularization\n",
    "- With `NUM_BLOCKS=10`, total is ~250K parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d8787de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "‚ïë                           SSM Model Summary                            ‚ïë\n",
      "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
      "‚ïë Components:                                                            ‚ïë\n",
      "‚ïë   Encoder:  LinearEncoder (256 params)                                 ‚ïë\n",
      "‚ïë   Blocks:   10√ó LinOSSBlock (total 250,880 params)                     ‚ïë\n",
      "‚ïë     [0] 25,088 params | IMEX | damp:‚úì | GLU(64‚Üí64) | drop:0.10         ‚ïë\n",
      "‚ïë     [1] 25,088 params | IMEX | damp:‚úì | GLU(64‚Üí64) | drop:0.10         ‚ïë\n",
      "‚ïë     [2] 25,088 params | IMEX | damp:‚úì | GLU(64‚Üí64) | drop:0.10         ‚ïë\n",
      "‚ïë     [3] 25,088 params | IMEX | damp:‚úì | GLU(64‚Üí64) | drop:0.10         ‚ïë\n",
      "‚ïë     [4] 25,088 params | IMEX | damp:‚úì | GLU(64‚Üí64) | drop:0.10         ‚ïë\n",
      "‚ïë     [5] 25,088 params | IMEX | damp:‚úì | GLU(64‚Üí64) | drop:0.10         ‚ïë\n",
      "‚ïë     [6] 25,088 params | IMEX | damp:‚úì | GLU(64‚Üí64) | drop:0.10         ‚ïë\n",
      "‚ïë     [7] 25,088 params | IMEX | damp:‚úì | GLU(64‚Üí64) | drop:0.10         ‚ïë\n",
      "‚ïë     [8] 25,088 params | IMEX | damp:‚úì | GLU(64‚Üí64) | drop:0.10         ‚ïë\n",
      "‚ïë     [9] 25,088 params | IMEX | damp:‚úì | GLU(64‚Üí64) | drop:0.10         ‚ïë\n",
      "‚ïë   Head:     ClassificationHead (650 params)                            ‚ïë\n",
      "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
      "‚ïë Total Parameters: 251,786                                              ‚ïë\n",
      "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599734b",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "We train our model using the **cross-entropy loss** for multi-class classification.\n",
    "\n",
    "### Implementation Details:\n",
    "\n",
    "- **Batched computation**: `jax.vmap` processes all samples in parallel for efficiency\n",
    "- **Stateful forward pass**: Model state (e.g., batch norm statistics) is threaded through computation\n",
    "- **Axis naming**: `axis_name=\"batch\"` enables collective operations across the batch dimension\n",
    "\n",
    "**Expected initial loss:** ~2.3 = log(10), which corresponds to random guessing among 10 classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4de2053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss shape: ()\n",
      "Initial loss value: 2.3367\n"
     ]
    }
   ],
   "source": [
    "def loss(\n",
    "    model: SSM,\n",
    "    x: Float[Array, \"batch 128 4\"],\n",
    "    y: Int[Array, \" batch\"],\n",
    "    state: eqx.nn.State,\n",
    "    key: PRNGKeyArray,\n",
    ") -> Float[Array, \"\"]:\n",
    "    \"\"\"Apply loss function to the model.\n",
    "\n",
    "    Returns the cross entropy loss given x and y as well as the updated model state.\n",
    "    \"\"\"\n",
    "    batch_keys = jax.random.split(key, x.shape[0])\n",
    "\n",
    "    # this vmap parallelizes the model over the batch dimension (which is the first dimension).\n",
    "    pred_y, model_state = jax.vmap(\n",
    "        model,\n",
    "        axis_name=\"batch\",\n",
    "        in_axes=(0, None, 0),\n",
    "        out_axes=(0, None),\n",
    "    )(x, state, batch_keys)\n",
    "    return cross_entropy(y, pred_y), model_state\n",
    "\n",
    "\n",
    "def cross_entropy(y: Int[Array, \" batch\"], pred_y: Float[Array, \"batch 10\"]) -> Float[Array, \"\"]:\n",
    "    \"\"\"Cross entropy loss function.\"\"\"\n",
    "    pred_y = jnp.take_along_axis(pred_y, jnp.expand_dims(y, 1), axis=1)\n",
    "    return -jnp.mean(pred_y)\n",
    "\n",
    "\n",
    "# Test the loss function on our sample batch\n",
    "loss_value, _ = loss(model, dummy_x, dummy_y, state, key)\n",
    "print(f\"Loss shape: {loss_value.shape}\")  # Should be scalar ()\n",
    "print(f\"Initial loss value: {loss_value:.4f}\")\n",
    "# Should be around log(10) ‚âà 2.3 for random predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d28ce3",
   "metadata": {},
   "source": [
    "### Testing Gradient Computation\n",
    "\n",
    "Before training, let's verify that gradients flow correctly through the model. We use `eqx.filter_value_and_grad` with `has_aux=True` to compute gradients while also getting the updated model state.\n",
    "\n",
    "**Note:** You may see a `ComplexWarning` - this is expected! LinOSS uses complex-valued internal representations that are converted to real values for reading out the hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f21816de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shox/dev/phd/ssm_dir/linax/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:5473: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n"
     ]
    }
   ],
   "source": [
    "(loss_value, new_state), grads = eqx.filter_value_and_grad(loss, has_aux=True)(\n",
    "    model, dummy_x, dummy_y, state, key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "812d27c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after gradient computation: 2.3367\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss after gradient computation: {loss_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f0a95",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "In addition to loss, we track **classification accuracy** to better understand model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bde466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = eqx.filter_jit(loss)  # JIT our loss function from earlier!\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def compute_accuracy(\n",
    "    model: SSM,\n",
    "    x: Float[Array, \"batch 128 4\"],\n",
    "    y: Int[Array, \" batch\"],\n",
    "    state: eqx.nn.State,\n",
    "    key: PRNGKeyArray,\n",
    ") -> Float[Array, \"\"]:\n",
    "    \"\"\"Computes the average accuracy on a batch.\"\"\"\n",
    "    batch_keys = jax.random.split(key, x.shape[0])\n",
    "\n",
    "    pred_y, _ = jax.vmap(\n",
    "        model,\n",
    "        axis_name=\"batch\",\n",
    "        in_axes=(0, None, 0),\n",
    "        out_axes=(0, None),\n",
    "    )(x, state, batch_keys)\n",
    "    pred_y = jnp.argmax(pred_y, axis=1)\n",
    "    return jnp.mean(y == pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44bc7f2",
   "metadata": {},
   "source": [
    "### Test Set Evaluation\n",
    "\n",
    "This function evaluates the model on the entire test set by iterating through all test batches.\n",
    "\n",
    "**Inference Mode**: We use `eqx.tree_inference(model, value=True)` to switch to inference mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92d4d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model: SSM,\n",
    "    testloader: torch.utils.data.DataLoader,\n",
    "    state: eqx.nn.State,\n",
    "    key: PRNGKeyArray,\n",
    "):\n",
    "    \"\"\"Evaluates the model on the test dataset.\"\"\"\n",
    "    inference_model = eqx.tree_inference(model, value=True)\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    for x, y in tqdm(testloader, desc=\"Evaluating\"):\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        # Note that all the JAX operations happen inside `loss` and `compute_accuracy`,\n",
    "        # and both have JIT wrappers, so this is fast.\n",
    "        avg_loss += loss(inference_model, x, y, state, key)[0]\n",
    "        avg_acc += compute_accuracy(inference_model, x, y, state, key)\n",
    "    return avg_loss / len(testloader), avg_acc / len(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e0cfd8",
   "metadata": {},
   "source": [
    "## Optimizer Setup\n",
    "\n",
    "We use the **AdamW** optimizer from Optax, which is Adam with decoupled weight decay regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9f58f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = optax.adamw(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2379e123",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Now let's train the model!\n",
    "\n",
    "### Expected Results:\n",
    "\n",
    "With the default configuration (`BATCH_SIZE=32`, `NUM_BLOCKS=10`, `STEPS=7500`):\n",
    "\n",
    "- **Initial accuracy**: ~10-12% (random guessing among 10 classes)\n",
    "- **After 1500 steps** (~1 epoch): ~91% accuracy\n",
    "- **After 3000 steps** (~2 epochs): ~94% accuracy\n",
    "- **After 7500 steps** (~5 epochs): **~96% accuracy**\n",
    "\n",
    "Training takes approximately **17 minutes** with these settings.\n",
    "\n",
    "Time to train!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c6780ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: SSM,\n",
    "    trainloader: torch.utils.data.DataLoader,\n",
    "    testloader: torch.utils.data.DataLoader,\n",
    "    optim: optax.GradientTransformation,\n",
    "    steps: int,\n",
    "    print_every: int,\n",
    "    state: eqx.nn.State,\n",
    "    key: PRNGKeyArray,\n",
    ") -> SSM:\n",
    "    \"\"\"Trains the model on the training dataset.\"\"\"\n",
    "    # Just like earlier: It only makes sense to train the arrays in our model,\n",
    "    # so filter out everything else.\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_inexact_array))\n",
    "\n",
    "    # Always wrap everything -- computing gradients, running the optimizer, updating\n",
    "    # the model -- into a single JIT region. This ensures things run as fast as\n",
    "    # possible.\n",
    "    @eqx.filter_jit\n",
    "    def make_step(\n",
    "        model: SSM,\n",
    "        opt_state: PyTree,\n",
    "        x: Float[Array, \"batch 128 4\"],\n",
    "        y: Int[Array, \" batch\"],\n",
    "        state: eqx.nn.State,\n",
    "        key: PRNGKeyArray,\n",
    "    ):\n",
    "        (loss_value, new_state), grads = eqx.filter_value_and_grad(loss, has_aux=True)(\n",
    "            model, x, y, state, key\n",
    "        )\n",
    "        updates, opt_state = optim.update(\n",
    "            grads, opt_state, eqx.filter(model, eqx.is_inexact_array)\n",
    "        )\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, loss_value, new_state\n",
    "\n",
    "    # Loop over our training dataset as many times as we need.\n",
    "    def infinite_trainloader():\n",
    "        while True:\n",
    "            yield from trainloader\n",
    "\n",
    "    key, train_key = jax.random.split(key, 2)\n",
    "\n",
    "    for step, (x, y) in zip(tqdm(range(steps)), infinite_trainloader()):\n",
    "        # PyTorch dataloaders give PyTorch tensors by default,\n",
    "        # so convert them to NumPy arrays.\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        model, opt_state, train_loss, new_state = make_step(\n",
    "            model, opt_state, x, y, state, train_key\n",
    "        )\n",
    "\n",
    "        if (step % print_every) == 0 or (step == steps - 1):\n",
    "            test_loss, test_accuracy = evaluate(model, testloader, new_state, key)\n",
    "            print(\n",
    "                f\"{step=}, train_loss={train_loss.item()}, \"\n",
    "                f\"test_loss={test_loss.item()}, test_accuracy={test_accuracy.item()}\"\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c34337cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:24<00:00, 12.73it/s]\n",
      "  0%|          | 2/7500 [00:33<28:29:19, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0, train_loss=2.368354082107544, test_loss=2.3261163234710693, test_accuracy=0.1006389781832695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 21.26it/s]\n",
      " 20%|‚ñà‚ñà        | 1502/7500 [04:00<5:22:17,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=1500, train_loss=0.6817602515220642, test_loss=0.3043871223926544, test_accuracy=0.9091453552246094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:16<00:00, 19.48it/s]\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 3002/7500 [07:31<4:24:02,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=3000, train_loss=0.12930883467197418, test_loss=0.1924053579568863, test_accuracy=0.9401956796646118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 21.57it/s]\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4502/7500 [10:57<2:38:41,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=4500, train_loss=0.5353334546089172, test_loss=0.17053061723709106, test_accuracy=0.9477835297584534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 21.48it/s]\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 6002/7500 [14:25<1:19:45,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=6000, train_loss=0.2455877959728241, test_loss=0.13679201900959015, test_accuracy=0.9574680328369141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 21.52it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [17:52<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=7499, train_loss=0.2593978941440582, test_loss=0.15777377784252167, test_accuracy=0.9515774846076965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train(model, trainloader, testloader, optim, STEPS, PRINT_EVERY, state, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9def091",
   "metadata": {},
   "source": [
    "In this notebook, you learned how to:\n",
    "- ‚úÖ Load and visualize sequential data (MNIST Sequence dataset)\n",
    "- ‚úÖ Configure and build a LinOSS model using Linax\n",
    "- ‚úÖ Set up training with JAX, Equinox, and Optax\n",
    "- ‚úÖ Train a state space model and monitor its performance\n",
    "\n",
    "**What's Next?** üöÄ\n",
    "\n",
    "Continue by exploring the next notebooks, where you'll dive deeper into:\n",
    "- SSM for regression problems\n",
    "- Advanced SSM architectures (LRU, S4, S5)\n",
    "- Configurable SSM architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8baeed",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. **Linax GitHub Repository**: https://github.com/camail-official/linax (‚≠ê Star the repo!)\n",
    "2. **LinOSS Paper**: Rusch, T. K., & Rus, D. (2024). \"Oscillatory State-Space Models\". https://openreview.net/forum?id=GRMfXcAAFh\n",
    "3. **Equinox Documentation**: https://docs.kidger.site/equinox/\n",
    "4. **JAX Documentation**: https://jax.readthedocs.io/\n",
    "5. **MNIST SEQUENCE Dataset**: https://edwin-de-jong.github.io/blog/mnist-sequence-data/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
